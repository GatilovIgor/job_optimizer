import os
import sys
import pandas as pd
from sqlalchemy import create_engine, text
from dotenv import load_dotenv
from pathlib import Path
from tqdm import tqdm

# --- 1. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø—É—Ç–µ–π ---
BASE_DIR = Path(__file__).resolve().parent.parent.parent
DATA_DIR = BASE_DIR / "data"
DATA_DIR.mkdir(exist_ok=True)
OUTPUT_FILE = DATA_DIR / "fact_vacancies_raw.csv"

# --- 2. –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥–∞ ---
dotenv_path = BASE_DIR / ".env"
load_dotenv(dotenv_path)


def load_data():
    print("--- üöÄ –°—Ç–∞—Ä—Ç –∑–∞–≥—Ä—É–∑–∫–∏ (–†–µ–∂–∏–º —Å—Ç—Ä–∏–º–∏–Ω–≥–∞) ---")

    db_dsn = os.getenv("DB_DSN")
    table_name = os.getenv("DB_TABLE_NAME", "fact_vacancies_cleaned")

    if not db_dsn:
        print("‚ùå –û–®–ò–ë–ö–ê: DB_DSN –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ .env")
        sys.exit(1)

    try:
        # –°–æ–∑–¥–∞–µ–º engine
        engine = create_engine(db_dsn)

        # 1. –°—á–∏—Ç–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ (–±—ã—Å—Ç—Ä–æ–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ)
        print("1Ô∏è‚É£  –°—á–∏—Ç–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫...")
        with engine.connect() as conn:
            count_query = text(f"SELECT COUNT(*) FROM {table_name}")
            total_rows = conn.execute(count_query).scalar()

        print(f"üìä –í—Å–µ–≥–æ —Å—Ç—Ä–æ–∫: {total_rows}")

        # 2. –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –ø–æ—Ç–æ–∫–æ–≤—É—é –≤—ã–≥—Ä—É–∑–∫—É
        # stream_results=True –û–ë–Ø–ó–ê–¢–ï–õ–ï–ù, —á—Ç–æ–±—ã –Ω–µ –≥—Ä—É–∑–∏—Ç—å –ø–∞–º—è—Ç—å
        conn = engine.connect().execution_options(stream_results=True)

        chunk_size = 2000

        print(f"2Ô∏è‚É£  –ù–∞—á–∏–Ω–∞—é —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ (–ø–æ {chunk_size} —Å—Ç—Ä–æ–∫)...")
        print("    –ï—Å–ª–∏ —Å–µ–π—á–∞—Å –Ω–µ –ø–æ–π–¥–µ—Ç ‚Äî –∑–Ω–∞—á–∏—Ç –∏–Ω—Ç–µ—Ä–Ω–µ—Ç —Å–æ–≤—Å–µ–º –ø–ª–æ—Ö–æ–π.")

        # –ü–µ—Ä–µ–¥–∞–µ–º conn (—Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ), –∞ –Ω–µ engine
        chunks = pd.read_sql(
            text(f"SELECT * FROM {table_name}"),
            conn,
            chunksize=chunk_size
        )

        with tqdm(total=total_rows, unit="row", desc="–°–∫–∞—á–∏–≤–∞–Ω–∏–µ") as pbar:
            for i, chunk in enumerate(chunks):
                mode = 'w' if i == 0 else 'a'
                header = (i == 0)

                chunk.to_csv(OUTPUT_FILE, mode=mode, index=False, header=header)
                pbar.update(len(chunk))

        # –ù–µ –∑–∞–±—ã–≤–∞–µ–º –∑–∞–∫—Ä—ã—Ç—å —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ
        conn.close()
        print(f"\n‚úÖ –ì–æ—Ç–æ–≤–æ! –§–∞–π–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {OUTPUT_FILE}")

    except KeyboardInterrupt:
        print("\nüõë –ü—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º.")
    except Exception as e:
        print(f"\n‚ùå –û–®–ò–ë–ö–ê: {e}")


if __name__ == "__main__":
    load_data()
