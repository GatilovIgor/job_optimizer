import os
import sys
import pandas as pd
from sqlalchemy import create_engine, text
from dotenv import load_dotenv
from pathlib import Path
from tqdm import tqdm

# --- 1. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø—É—Ç–µ–π ---
BASE_DIR = Path(__file__).resolve().parent.parent.parent
DATA_DIR = BASE_DIR / "data"
DATA_DIR.mkdir(exist_ok=True)

# –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –æ—Ç–¥–µ–ª—å–Ω—ã–π —Ñ–∞–π–ª, —á—Ç–æ–±—ã –Ω–µ –∑–∞—Ç–µ—Ä–µ—Ç—å –æ—Å–Ω–æ–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
OUTPUT_FILE = DATA_DIR / "fact_vacancies_test.csv"

# --- 2. –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Ç–∞–±–ª–∏—Ü—ã ---
# –ñ–µ—Å—Ç–∫–æ –ø—Ä–æ–ø–∏—Å—ã–≤–∞–µ–º –∏–º—è —Ç–µ—Å—Ç–æ–≤–æ–π —Ç–∞–±–ª–∏—Ü—ã
TARGET_TABLE = "fact_vacancies_cleaned_test"

# --- 3. –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥–∞ (.env) ---
dotenv_path = BASE_DIR / ".env"
load_dotenv(dotenv_path)


def load_test_data():
    print(f"--- üß™ –°—Ç–∞—Ä—Ç –∑–∞–≥—Ä—É–∑–∫–∏ –¢–ï–°–¢–û–í–´–• –¥–∞–Ω–Ω—ã—Ö ({TARGET_TABLE}) ---")

    # –ë–µ—Ä–µ–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∏–∑ —Ç–æ–≥–æ –∂–µ .env
    db_dsn = os.getenv("DB_DSN")

    if not db_dsn:
        print("‚ùå –û–®–ò–ë–ö–ê: DB_DSN –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ .env")
        sys.exit(1)

    try:
        engine = create_engine(db_dsn)

        # –®–∞–≥ 1: –°—á–∏—Ç–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫
        print("üìä –ü–æ–¥—Å—á–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å—Ç—Ä–æ–∫...")
        with engine.connect() as conn:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º text() –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ–≥–æ SQL
            count_query = text(f"SELECT COUNT(*) FROM {TARGET_TABLE}")
            total_rows = conn.execute(count_query).scalar()

        print(f"–í—Å–µ–≥–æ —Å—Ç—Ä–æ–∫ –≤ —Ç–µ—Å—Ç–µ: {total_rows}")

        if total_rows == 0:
            print("‚ö†Ô∏è –¢–µ—Å—Ç–æ–≤–∞—è —Ç–∞–±–ª–∏—Ü–∞ –ø—É—Å—Ç–∞.")
            return

        # –®–∞–≥ 2: –°–∫–∞—á–∏–≤–∞–µ–º —Å –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–æ–º
        chunk_size = 5000

        with tqdm(total=total_rows, unit="row", desc="–°–∫–∞—á–∏–≤–∞–Ω–∏–µ —Ç–µ—Å—Ç–∞") as pbar:
            chunks = pd.read_sql(f"SELECT * FROM {TARGET_TABLE}", engine, chunksize=chunk_size)

            for i, chunk in enumerate(chunks):
                mode = 'w' if i == 0 else 'a'
                header = (i == 0)

                chunk.to_csv(OUTPUT_FILE, mode=mode, index=False, header=header)
                pbar.update(len(chunk))

        print(f"\n‚úÖ –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {OUTPUT_FILE}")

    except Exception as e:
        print(f"\n‚ùå –û–®–ò–ë–ö–ê: {e}")


if __name__ == "__main__":
    load_test_data()
