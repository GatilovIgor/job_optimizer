import pandas as pd
import numpy as np
import json
from html.parser import HTMLParser
from datetime import datetime


# --- –£—Ç–∏–ª–∏—Ç–∞ –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ HTML ---
class MLStripper(HTMLParser):
    def __init__(self):
        super().__init__()
        self.reset()
        self.strict = False
        self.convert_charrefs = True
        self.text = []

    def handle_data(self, d):
        self.text.append(d)

    def get_data(self):
        return "".join(self.text)


def strip_tags(html):
    if not isinstance(html, str): return ""
    s = MLStripper()
    s.feed(html)
    return " ".join(s.get_data().split())


def prepare_dataset(input_csv: str, output_parquet: str):
    print(f"üì• Loading {input_csv}...")
    df = pd.read_csv(input_csv)

    # 1. –ü–∞—Ä—Å–∏–Ω–≥ –¥–∞—Ç
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º last_update_date –∫–∞–∫ "—Ç–µ–∫—É—â–∏–π –º–æ–º–µ–Ω—Ç" –¥–ª—è —Å–Ω—ç–ø—à–æ—Ç–∞
    now_date = pd.to_datetime(df['last_update_date']).max()
    df['pub_date'] = pd.to_datetime(df['publication_date'])

    # –°—á–∏—Ç–∞–µ–º –≤—Ä–µ–º—è –∂–∏–∑–Ω–∏ –≤–∞–∫–∞–Ω—Å–∏–∏ –≤ –¥–Ω—è—Ö (–º–∏–Ω–∏–º—É–º 1 –¥–µ–Ω—å, —á—Ç–æ–±—ã –Ω–µ –¥–µ–ª–∏—Ç—å –Ω–∞ 0)
    df['days_live'] = (now_date - df['pub_date']).dt.total_seconds() / (24 * 3600)
    df['days_live'] = df['days_live'].apply(lambda x: max(x, 1))

    # 2. –†–∞—Å—á–µ—Ç Velocity (–û—Ç–∫–ª–∏–∫–æ–≤ –≤ –¥–µ–Ω—å)
    # –ó–∞–º–µ–Ω—è–µ–º total_responses NaN –Ω–∞ 0
    df['total_responses'] = df['total_responses'].fillna(0)
    df['velocity'] = df['total_responses'] / df['days_live']

    # 3. –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ Top Performer (–£—Å–ø–µ—à–Ω–∞—è –≤–∞–∫–∞–Ω—Å–∏—è)
    # –õ–æ–≥–∏–∫–∞: –í–∞–∫–∞–Ω—Å–∏—è —É—Å–ø–µ—à–Ω–∞, –µ—Å–ª–∏ –µ—ë —Å–∫–æ—Ä–æ—Å—Ç—å –≤—ã—à–µ —Å—Ä–µ–¥–Ω–µ–π –ø–æ —ç—Ç–æ–º—É –ø—Ä–æ—Ñ–∏–ª—é
    # –°—á–∏—Ç–∞–µ–º Z-score –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏ –≤–Ω—É—Ç—Ä–∏ –∫–∞–∂–¥–æ–≥–æ Profile

    # –°–Ω–∞—á–∞–ª–∞ —Å–≥—Ä—É–ø–ø–∏—Ä—É–µ–º –∏ –ø–æ—Å—á–∏—Ç–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
    profile_stats = df.groupby('profile')['velocity'].agg(['mean', 'std']).reset_index()
    df = df.merge(profile_stats, on='profile', suffixes=('', '_stats'))

    # –ï—Å–ª–∏ std = 0 (–æ–¥–Ω–∞ –≤–∞–∫–∞–Ω—Å–∏—è –≤ –ø—Ä–æ—Ñ–∏–ª–µ), z_score = 0
    df['velocity_z'] = (df['velocity'] - df['mean']) / df['std'].replace(0, 1)

    # –£—Å–ª–æ–≤–∏–µ —É—Å–ø–µ—Ö–∞: –¢–æ–ø 30% (Z-score > 0.5) –ò–õ–ò –ø—Ä–æ—Å—Ç–æ –º–Ω–æ–≥–æ –æ—Ç–∫–ª–∏–∫–æ–≤ (> 1 –≤ –¥–µ–Ω—å)
    # –§–∏–ª—å—Ç—Ä—É–µ–º —Å–æ–≤—Å–µ–º –Ω–æ–≤—ã–µ –≤–∞–∫–∞–Ω—Å–∏–∏ (< 3 –¥–Ω–µ–π), —á—Ç–æ–±—ã –Ω–µ –≤–Ω–æ—Å–∏—Ç—å —à—É–º
    df['is_top_performer'] = (
            ((df['velocity_z'] > 0.5) | (df['velocity'] > 1.0)) &
            (df['days_live'] >= 3)
    )

    print(f"üèÜ Identified {df['is_top_performer'].sum()} top performers out of {len(df)} vacancies.")

    # 4. –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞
    print("üßπ Cleaning text...")
    df['text_clean'] = df['vacancy_description'].apply(strip_tags)

    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–∞–≤—ã–∫–æ–≤ (JSON -> String)
    def clean_skills(x):
        try:
            return " ".join(json.loads(x))
        except:
            return ""

    df['skills_str'] = df['skills'].apply(clean_skills)

    # 5. –û—Ç–±–æ—Ä –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è RAG
    # –ù–∞–º –Ω—É–∂–Ω—ã:
    # - vacancy_title, skills_str, specialization, text_clean (–¥–ª—è –ø–æ–∏—Å–∫–∞)
    # - vacancy_description (RAW HTML –¥–ª—è LLM, —á—Ç–æ–±—ã –æ–Ω–∞ —É—á–∏–ª–∞—Å—å —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—é)
    # - velocity (–¥–ª—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏)
    # - is_top_performer (–¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞)

    final_cols = [
        'vacancy_title',
        'vacancy_description',
        'text_clean',
        'skills_str',
        'specialization',
        'profile',
        'velocity',
        'is_top_performer'
    ]

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º
    df[final_cols].to_parquet(output_parquet, index=False)
    print(f"‚úÖ Saved processed dataset to {output_parquet}")


if __name__ == "__main__":
    # –ó–∞–ø—É—Å–∫: python src/data/prepare.py
    prepare_dataset('vacancies_export.csv', 'dataset/vacancies_processed.parquet')
