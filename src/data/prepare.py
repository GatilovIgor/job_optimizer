import pandas as pd
import numpy as np
import pathlib
from html.parser import HTMLParser

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø—É—Ç–µ–π
ROOT_DIR = pathlib.Path(__file__).resolve().parent.parent.parent
DATA_DIR = ROOT_DIR / "dataset"
DATA_DIR.mkdir(exist_ok=True)


class MLStripper(HTMLParser):
    def __init__(self):
        super().__init__()
        self.reset()
        self.strict = False
        self.convert_charrefs = True
        self.text = []

    def handle_data(self, d):
        self.text.append(d)

    def get_data(self):
        return "".join(self.text)


def strip_tags(html_txt):
    if not isinstance(html_txt, str): return ""
    s = MLStripper()
    s.feed(html_txt)
    return " ".join(s.get_data().split())


def parse_pg_array(array_str):
    """–ü–∞—Ä—Å–∏—Ç —Å—Ç—Ä–æ–∫—É '{1,2,3}' –≤ —Å–ø–∏—Å–æ–∫ [1, 2, 3]"""
    if pd.isna(array_str) or str(array_str) == '{}': return []
    content = str(array_str).strip('{}')
    if not content: return []
    return [int(x) for x in content.split(',') if x.strip().isdigit()]


def prepare_dataset(input_csv: str, output_parquet: str):
    print(f"üì• –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ {input_csv}...")

    # 1. –ó–∞–≥—Ä—É–∑–∫–∞ –æ—Å–Ω–æ–≤–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    df = pd.read_csv(input_csv)

    # 2. –ó–∞–≥—Ä—É–∑–∫–∞ —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∞ –Ω–∞–≤—ã–∫–æ–≤ (–ø–µ—Ä–µ–≤–æ–¥—á–∏–∫ –∏–∑ ID –≤ —Ç–µ–∫—Å—Ç)
    skills_map_path = ROOT_DIR / "skills.csv"
    if skills_map_path.exists():
        print("üîó –ó–∞–≥—Ä—É–∑–∫–∞ —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∞ –Ω–∞–≤—ã–∫–æ–≤ skills.csv...")
        df_skills = pd.read_csv(skills_map_path)
        skill_map = dict(zip(df_skills['skill_id'], df_skills['name']))
    else:
        print("‚ö†Ô∏è –í–ù–ò–ú–ê–ù–ò–ï: skills.csv –Ω–µ –Ω–∞–π–¥–µ–Ω! –ù–∞–≤—ã–∫–∏ –±—É–¥—É—Ç –ø—É—Å—Ç—ã–º–∏.")
        skill_map = {}

    # 3. –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞—Ç –∏ Velocity
    df['upd_date'] = pd.to_datetime(df['last_update_date'])
    df['pub_date'] = pd.to_datetime(df['publication_date'])

    # –°—á–∏—Ç–∞–µ–º –≤—Ä–µ–º—è –∂–∏–∑–Ω–∏ (–º–∏–Ω–∏–º—É–º 0.5 –¥–Ω—è, —á—Ç–æ–±—ã –Ω–µ –¥–µ–ª–∏—Ç—å –Ω–∞ 0)
    df['days_live'] = (df['upd_date'] - df['pub_date']).dt.total_seconds() / (24 * 3600)
    df['days_live'] = df['days_live'].apply(lambda x: max(x, 0.5))

    # Velocity: —Å–∫–æ–ª—å–∫–æ –æ—Ç–∫–ª–∏–∫–æ–≤ –≤ –¥–µ–Ω—å
    df['total_responses'] = df['total_responses'].fillna(0)
    df['velocity'] = df['total_responses'] / df['days_live']

    # 4. –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ Top Performers (–£—Å–ø–µ—à–Ω—ã–µ)
    # –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –º–∞–ª–æ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –≤—ã–≥—Ä—É–∑–∫–∞ –∑–∞ 2 –¥–Ω—è), –º—ã —Å–Ω–∏–∂–∞–µ–º –ø–ª–∞–Ω–∫—É
    # –í–∞–∫–∞–Ω—Å–∏—è —Å—á–∏—Ç–∞–µ—Ç—Å—è —É—Å–ø–µ—à–Ω–æ–π, –µ—Å–ª–∏ —É –Ω–µ—ë > 0.1 –æ—Ç–∫–ª–∏–∫–∞ –≤ –¥–µ–Ω—å
    df['is_top_performer'] = df['velocity'] > 0.1

    # –ï—Å–ª–∏ –≤—Å–µ —Ä–∞–≤–Ω–æ 0 —É—Å–ø–µ—à–Ω—ã—Ö, –±–µ—Ä–µ–º –ø—Ä–æ—Å—Ç–æ —Ç–æ–ø 10% —Å–∞–º—ã—Ö –∞–∫—Ç–∏–≤–Ω—ã—Ö
    if df['is_top_performer'].sum() == 0:
        threshold = df['velocity'].quantile(0.9)
        df['is_top_performer'] = df['velocity'] >= threshold

    print(f"üèÜ –ù–∞–π–¥–µ–Ω–æ —ç—Ç–∞–ª–æ–Ω–Ω—ã—Ö –≤–∞–∫–∞–Ω—Å–∏–π: {df['is_top_performer'].sum()} –∏–∑ {len(df)}")

    # 5. –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤ –∏ –Ω–∞–≤—ã–∫–æ–≤
    print("üßπ –û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ –∏ –º–∞–ø–ø–∏–Ω–≥ –Ω–∞–≤—ã–∫–æ–≤...")
    df['text_clean'] = df['vacancy_description'].apply(strip_tags)

    # –ü—Ä–µ–≤—Ä–∞—â–∞–µ–º ID {1,2} –≤ —Ç–µ–∫—Å—Ç "–ù–∞–≤—ã–∫1, –ù–∞–≤—ã–∫2"
    def map_skills(val):
        ids = parse_pg_array(val)
        return ", ".join([skill_map.get(i, "") for i in ids if i in skill_map])

    # –í CSV –∫–æ–ª–æ–Ω–∫–∞ –Ω–∞–∑—ã–≤–∞–µ—Ç—Å—è skill_ids (–∏–∑ –≤–∞—à–µ–≥–æ SQL)
    if 'skill_ids' in df.columns:
        df['skills_str'] = df['skill_ids'].apply(map_skills)
    else:
        df['skills_str'] = ""

    # 6. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
    final_cols = [
        'vacancy_title',
        'vacancy_description',
        'text_clean',
        'skills_str',
        'specialization',
        'profile',
        'velocity',
        'is_top_performer'
    ]

    df[final_cols].to_parquet(output_parquet, index=False)
    print(f"‚úÖ –ì–æ—Ç–æ–≤—ã–π –¥–∞—Ç–∞—Å–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_parquet}")


if __name__ == "__main__":
    prepare_dataset('vacancies_export.csv', 'dataset/vacancies_processed.parquet')
