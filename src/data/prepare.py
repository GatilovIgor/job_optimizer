import pandas as pd
import numpy as np
import pathlib
from tqdm import tqdm  # –ù—É–∂–Ω–∞ –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ tqdm –¥–ª—è –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–∞

# --- –ù–ê–°–¢–†–û–ô–ö–ê –ü–£–¢–ï–ô ---
CURRENT_DIR = pathlib.Path(__file__).resolve().parent
ROOT_DIR = CURRENT_DIR.parent.parent
DATA_DIR = ROOT_DIR / "data"

# –ü–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è –Ω–∞ –ë–û–õ–¨–®–û–ô —Ñ–∞–π–ª
RAW_FILE = DATA_DIR / "fact_vacancies_raw.csv"
OUTPUT_FILE = DATA_DIR / "vacancies_processed.parquet"

# –ö–æ–ª–æ–Ω–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –Ω–∞–º —Ä–µ–∞–ª—å–Ω–æ –Ω—É–∂–Ω—ã (—á—Ç–æ–±—ã —ç–∫–æ–Ω–æ–º–∏—Ç—å –ø–∞–º—è—Ç—å)
# –ù–µ –≥—Ä—É–∑–∏–º –ª–∏—à–Ω–∏–π –º—É—Å–æ—Ä —Ç–∏–ø–∞ source, company_original –∏ —Ç.–¥.
REQUIRED_COLS = [
    'vacancy_id', 'loaded_at', 'total_responses',
    'profile', 'city', 'vacancy_title',
    'vacancy_description', 'specialization'
]


def calculate_peak_efficiency(dates, responses, window_days=7):
    """
    –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ä–∞—Å—á–µ—Ç —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –Ω–∞ NumPy.
    """
    n = len(dates)
    if n < 2: return 0.0

    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ –Ω–∞–Ω–æ—Å–µ–∫—É–Ω–¥—ã –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è, –µ—Å–ª–∏ —ç—Ç–æ datetime64
    # –ù–æ –ø—Ä–æ—â–µ —Ä–∞–±–æ—Ç–∞—Ç—å —Å –∏–Ω–¥–µ–∫—Å–∞–º–∏, —Ç–∞–∫ –∫–∞–∫ –º–∞—Å—Å–∏–≤ –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω

    best_eff = 0.0

    # –û–∫–Ω–æ –≤ –Ω–∞–Ω–æ—Å–µ–∫—É–Ω–¥–∞—Ö (7 –¥–Ω–µ–π)
    window_ns = np.timedelta64(window_days, 'D').astype('timedelta64[ns]').astype(np.int64)
    dates_ns = dates.astype(np.int64)

    # –ü—Ä–æ—Ö–æ–¥–∏–º –ø–æ –º–∞—Å—Å–∏–≤—É
    for i in range(n):
        start_time = dates_ns[i]
        limit_time = start_time + window_ns

        # –ë–∏–Ω–∞—Ä–Ω—ã–π –ø–æ–∏—Å–∫ –∫–æ–Ω—Ü–∞ –æ–∫–Ω–∞ (–æ—á–µ–Ω—å –±—ã—Å—Ç—Ä–æ)
        end_idx = np.searchsorted(dates_ns, limit_time, side='right') - 1

        if end_idx <= i: continue

        val_start = responses[i]
        val_end = responses[end_idx]

        current_eff = 0

        if val_start > 0:
            current_eff = val_end - val_start
        else:
            # –õ–æ–≥–∏–∫–∞ "–ø–µ—Ä–≤–æ–≥–æ –Ω–µ–Ω—É–ª–µ–≤–æ–≥–æ"
            # –°—Ä–µ–∑ –≤–Ω—É—Ç—Ä–∏ –æ–∫–Ω–∞
            window_slice = responses[i: end_idx + 1]
            # np.argmax –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–Ω–¥–µ–∫—Å –ø–µ—Ä–≤–æ–≥–æ True (–∏–ª–∏ 0)
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –≤–æ–æ–±—â–µ –∑–Ω–∞—á–µ–Ω–∏—è > 0
            is_nonzero = window_slice > 0
            if is_nonzero.any():
                first_nonzero_idx = np.argmax(is_nonzero)
                first_val = window_slice[first_nonzero_idx]
                current_eff = val_end - first_val
            else:
                current_eff = 0

        if current_eff > best_eff:
            best_eff = current_eff

    return float(best_eff)


def main():
    print(f"üöÄ –†–∞–±–æ—á–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {ROOT_DIR}")
    print(f"üìÇ –ó–∞–≥—Ä—É–∑–∫–∞ –±–æ–ª—å—à–æ–≥–æ —Ñ–∞–π–ª–∞: {RAW_FILE.name}...")

    if not RAW_FILE.exists():
        print(f"‚ùå –§–∞–π–ª {RAW_FILE} –Ω–µ –Ω–∞–π–¥–µ–Ω!")
        return

    # 1. –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–æ–ª—å–∫–æ –Ω—É–∂–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
    try:
        df = pd.read_csv(
            RAW_FILE,
            usecols=lambda c: c in REQUIRED_COLS,  # –ì—Ä—É–∑–∏–º —Ç–æ–ª—å–∫–æ —Ç–æ, —á—Ç–æ –µ—Å—Ç—å –≤ —Å–ø–∏—Å–∫–µ
            low_memory=False
        )
    except ValueError as e:
        # –ï—Å–ª–∏ –≤–¥—Ä—É–≥ –Ω–∞–∑–≤–∞–Ω–∏—è –∫–æ–ª–æ–Ω–æ–∫ –æ—Ç–ª–∏—á–∞—é—Ç—Å—è (–Ω–∞–ø—Ä–∏–º–µ—Ä –Ω–µ—Ç profile), –ø—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å –≤—Å—ë
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –∫–æ–ª–æ–Ω–æ–∫ ({e}), –ø—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å –≤—Å—ë...")
        df = pd.read_csv(RAW_FILE, low_memory=False)

    print(f"üì¶ –ó–∞–≥—Ä—É–∂–µ–Ω–æ —Å—Ç—Ä–æ–∫: {len(df)}")

    # –ü—Ä–∏–≤–æ–¥–∏–º —Ç–∏–ø—ã
    df['loaded_at'] = pd.to_datetime(df['loaded_at'])
    df['total_responses'] = df['total_responses'].fillna(0).astype(int)
    # –ü—Ä–∏–≤–æ–¥–∏–º ID –∫ —Å—Ç—Ä–æ–∫–µ, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –ø—É—Ç–∞–Ω–∏—Ü—ã int/str
    df['vacancy_id'] = df['vacancy_id'].astype(str)

    print("‚è≥ –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –ø–æ –≤–∞–∫–∞–Ω—Å–∏—è–º...")
    grouped = df.groupby('vacancy_id')
    unique_vacancies = len(grouped)
    print(f"üÜî –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –≤–∞–∫–∞–Ω—Å–∏–π: {unique_vacancies}")

    print("üß† –†–∞—Å—á–µ—Ç –ø–∏–∫–æ–≤–æ–π —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ (—ç—Ç–æ –∑–∞–π–º–µ—Ç –≤—Ä–µ–º—è)...")

    results = []

    # –ò—Å–ø–æ–ª—å–∑—É–µ–º tqdm –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–∞
    for vac_id, group in tqdm(grouped, total=unique_vacancies, unit="vac"):
        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–∞ –¥–ª—è –ª–æ–≥–∏–∫–∏ –æ–∫–Ω–∞
        group = group.sort_values('loaded_at')

        # –ò–∑–≤–ª–µ–∫–∞–µ–º numpy –º–∞—Å—Å–∏–≤—ã –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
        dates = group['loaded_at'].values
        responses = group['total_responses'].values

        eff = calculate_peak_efficiency(dates, responses)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º "—Å–≤–µ–∂–∞–π—à—É—é" –≤–µ—Ä—Å–∏—é –æ–ø–∏—Å–∞–Ω–∏—è
        # (iloc[-1] –±–µ—Ä–µ—Ç –ø–æ—Å–ª–µ–¥–Ω—é—é –∑–∞–ø–∏—Å—å –ø–æ –≤—Ä–µ–º–µ–Ω–∏)
        best_row = group.iloc[-1].to_dict()
        best_row['efficiency'] = eff

        # –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–µ–µ –∏–∑ —Å–ª–æ–≤–∞—Ä—è, —á—Ç–æ–±—ã –Ω–µ –¥—É–±–ª–∏—Ä–æ–≤–∞—Ç—å –ø–∞–º—è—Ç—å
        # (loaded_at –∏ total_responses –Ω–∞–º –≤ RAG —É–∂–µ –Ω–µ –Ω—É–∂–Ω—ã, –Ω—É–∂–Ω–∞ —Ç–æ–ª—å–∫–æ –º–µ—Ç—Ä–∏–∫–∞)
        del best_row['loaded_at']
        del best_row['total_responses']

        results.append(best_row)

    result_df = pd.DataFrame(results)

    # –ê–Ω–∞–ª–∏—Ç–∏–∫–∞ –ø–æ –º–µ—Ç—Ä–∏–∫–µ
    max_eff = result_df['efficiency'].max()
    avg_eff = result_df['efficiency'].mean()
    print(f"\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏:")
    print(f"   –ú–∞–∫—Å–∏–º—É–º: {max_eff:.1f} –æ—Ç–∫–ª–∏–∫–æ–≤/–Ω–µ–¥–µ–ª—é")
    print(f"   –°—Ä–µ–¥–Ω–µ–µ:  {avg_eff:.1f} –æ—Ç–∫–ª–∏–∫–æ–≤/–Ω–µ–¥–µ–ª—é")

    # –¢–æ–ø –ø–µ—Ä—Ñ–æ—Ä–º–µ—Ä—ã (Top 20%)
    # –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –º–∞–ª–æ –∏–ª–∏ –≤—Å–µ –Ω—É–ª–∏, –±–µ—Ä–µ–º —Ö–æ—Ç—è –±—ã > 0
    threshold = result_df['efficiency'].quantile(0.8)
    if threshold == 0 and max_eff > 0:
        print("‚ö†Ô∏è 80-–π –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª—å —Ä–∞–≤–µ–Ω 0. –ë—É–¥–µ–º —Å—á–∏—Ç–∞—Ç—å —Ç–æ–ø–∞–º–∏ –≤—Å–µ—Ö, —É –∫–æ–≥–æ > 0.")
        threshold = 1.0

    result_df['is_top_performer'] = result_df['efficiency'] >= threshold

    top_count = result_df['is_top_performer'].sum()
    print(f"üèÜ –ü–æ—Ä–æ–≥ Top-20%: {threshold:.1f}")
    print(f"üåü –≠—Ç–∞–ª–æ–Ω–Ω—ã—Ö –≤–∞–∫–∞–Ω—Å–∏–π –æ—Ç–æ–±—Ä–∞–Ω–æ: {top_count}")

    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
    print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ Parquet...")
    result_df.to_parquet(OUTPUT_FILE, index=False)
    print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ! –§–∞–π–ª –≥–æ—Ç–æ–≤: {OUTPUT_FILE}")


if __name__ == "__main__":
    main()
