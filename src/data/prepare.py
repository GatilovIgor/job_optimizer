import pandas as pd
import numpy as np
import pathlib
from html.parser import HTMLParser

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø—É—Ç–µ–π
ROOT_DIR = pathlib.Path(__file__).resolve().parent.parent.parent
DATA_DIR = ROOT_DIR / "dataset"
DATA_DIR.mkdir(exist_ok=True)


class MLStripper(HTMLParser):
    def __init__(self):
        super().__init__()
        self.reset()
        self.strict = False
        self.convert_charrefs = True
        self.text = []

    def handle_data(self, d):
        self.text.append(d)

    def get_data(self):
        return "".join(self.text)


def strip_tags(html_txt):
    if not isinstance(html_txt, str): return ""
    s = MLStripper()
    s.feed(html_txt)
    return " ".join(s.get_data().split())


def parse_pg_array(array_str):
    if pd.isna(array_str) or str(array_str) == '{}': return []
    content = str(array_str).strip('{}')
    return [int(x) for x in content.split(',') if x.strip().isdigit()]


def prepare_dataset(input_csv: str, output_parquet: str):
    print(f"üì• –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ {input_csv}...")
    df = pd.read_csv(input_csv)

    # 1. –ó–∞–≥—Ä—É–∑–∫–∞ –Ω–∞–≤—ã–∫–æ–≤
    skills_map_path = ROOT_DIR / "skills.csv"
    skill_map = {}
    if skills_map_path.exists():
        df_skills = pd.read_csv(skills_map_path)
        skill_map = dict(zip(df_skills['skill_id'], df_skills['name']))

    # 2. –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞—Ç –∏ —Ä–∞—Å—á–µ—Ç Velocity
    df['upd_date'] = pd.to_datetime(df['last_update_date'])
    df['pub_date'] = pd.to_datetime(df['publication_date'])
    # –°—á–∏—Ç–∞–µ–º –≤—Ä–µ–º—è –∂–∏–∑–Ω–∏ (–º–∏–Ω–∏–º—É–º 0.1 –¥–Ω—è –¥–ª—è —Å–æ–≤—Å–µ–º –Ω–æ–≤—ã—Ö)
    df['days_live'] = (df['upd_date'] - df['pub_date']).dt.total_seconds() / (24 * 3600)
    df['days_live'] = df['days_live'].apply(lambda x: max(x, 0.1))

    df['total_responses'] = df['total_responses'].fillna(0)
    df['velocity'] = df['total_responses'] / df['days_live']

    # 3. –ì–ò–ë–ö–ò–ô –§–ò–õ–¨–¢–† –£–°–ü–ï–•–ê
    print("üèÜ –û—Ç–±–æ—Ä —ç—Ç–∞–ª–æ–Ω–Ω—ã—Ö –≤–∞–∫–∞–Ω—Å–∏–π...")

    # –°—á–∏—Ç–∞–µ–º –ø–æ—Ä–æ–≥ 80-–≥–æ –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª—è (—Ç–æ–ø-20%) –ø–æ –≤—Å–µ–π –±–∞–∑–µ
    velocity_threshold = df['velocity'].quantile(0.8)

    # –ï—Å–ª–∏ –≤—Å–µ –≤–∞–∫–∞–Ω—Å–∏–∏ –∏–º–µ—é—Ç 0 –æ—Ç–∫–ª–∏–∫–æ–≤, –ø–æ—Ä–æ–≥ –±—É–¥–µ—Ç 0. –í —ç—Ç–æ–º —Å–ª—É—á–∞–µ –±–µ—Ä–µ–º –ø—Ä–æ—Å—Ç–æ —Ç–æ–ø –ø–æ –¥–ª–∏–Ω–µ —Ç–µ–∫—Å—Ç–∞.
    if velocity_threshold == 0:
        print("‚ö†Ô∏è –ú–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö –æ–± –æ—Ç–∫–ª–∏–∫–∞—Ö, –æ—Ç–±–∏—Ä–∞—é –ø–æ –∫–∞—á–µ—Å—Ç–≤—É –æ–ø–∏—Å–∞–Ω–∏—è...")
        df['is_top_performer'] = df['vacancy_description'].str.len() > df['vacancy_description'].str.len().median()
    else:
        # –£—Å–ª–æ–≤–∏–µ: –≤—ã—à–µ –ø–æ—Ä–æ–≥–∞ –ò —Ç–µ–∫—Å—Ç –±–æ–ª—å—à–µ 300 —Å–∏–º–≤–æ–ª–æ–≤
        df['is_top_performer'] = (df['velocity'] >= velocity_threshold) & (df['vacancy_description'].str.len() > 300)

    # –ï—Å–ª–∏ –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–æ–≤ –≤—Å—ë –µ—â–µ 0, –±–µ—Ä–µ–º –ø—Ä–æ—Å—Ç–æ —Ç–æ–ø-100 –ø–æ —Å–∫–æ—Ä–æ—Å—Ç–∏
    if df['is_top_performer'].sum() == 0:
        df.loc[df.nlargest(100, 'velocity').index, 'is_top_performer'] = True

    # 4. –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤ –∏ –Ω–∞–≤—ã–∫–æ–≤
    print("üßπ –û—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏ –º–∞–ø–ø–∏–Ω–≥ –Ω–∞–≤—ã–∫–æ–≤...")
    df['text_clean'] = df['vacancy_description'].apply(strip_tags)

    def map_skills(val):
        ids = parse_pg_array(val)
        return ", ".join([skill_map.get(i, "") for i in ids if i in skill_map])

    if 'skill_ids' in df.columns:
        df['skills_str'] = df['skill_ids'].apply(map_skills)
    else:
        df['skills_str'] = ""

    # 5. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
    final_cols = ['vacancy_title', 'vacancy_description', 'text_clean', 'skills_str',
                  'specialization', 'profile', 'velocity', 'is_top_performer']

    df[final_cols].to_parquet(output_parquet, index=False)
    print(f"‚úÖ –ì–æ—Ç–æ–≤–æ! –°–æ–±—Ä–∞–Ω–æ –≤–∞–∫–∞–Ω—Å–∏–π: {len(df)}. –≠—Ç–∞–ª–æ–Ω–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è: {df['is_top_performer'].sum()}")


if __name__ == "__main__":
    prepare_dataset('vacancies_export.csv', 'dataset/vacancies_processed.parquet')
