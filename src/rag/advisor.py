from typing import List, Dict
import re
import html
import time
from src.rag.llm import LocalLLM
from src.api.models import VacancyIn, VacancyOut
from src.common.text import normalize_text


class VacancyAdvisor:
    def __init__(self):
        print("üîß Initializing Single-Field Advisor...", flush=True)
        self.llm = LocalLLM()

    def _clean_html(self, raw_text: str) -> str:
        """–û—á–∏—â–∞–µ—Ç —Ç–µ–∫—Å—Ç –æ—Ç HTML-—Ç–µ–≥–æ–≤ –∏ —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª–æ–≤"""
        if not raw_text: return ""
        text = html.unescape(raw_text)
        # –ó–∞–º–µ–Ω—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–µ —Ç–µ–≥–∏ –Ω–∞ –ø–µ—Ä–µ–Ω–æ—Å—ã
        text = re.sub(r'<li>', '\n‚Ä¢ ', text)
        text = re.sub(r'<br\s*/?>', '\n', text)
        text = re.sub(r'</p>|</div>', '\n\n', text)
        # –£–¥–∞–ª—è–µ–º –≤—Å–µ –æ—Å—Ç–∞–ª—å–Ω—ã–µ —Ç–µ–≥–∏
        text = re.sub(r'<[^>]+>', '', text)
        # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
        text = re.sub(r'\n\s*\n', '\n\n', text)
        return text.strip()

    def _analyze_quality(self, text: str) -> Dict:
        """–ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ (0-100)"""
        score = 0
        issues = []
        text_lower = text.lower()

        # –ï—Å–ª–∏ —Ç–µ–∫—Å—Ç–∞ –Ω–µ—Ç —Å–æ–≤—Å–µ–º –∏–ª–∏ –æ–Ω –æ—á–µ–Ω—å –∫–æ—Ä–æ—Ç–∫–∏–π (–≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å –Ω—É–ª—è)
        if len(text) < 50:
            return {"score": 0, "issues": ["–¢–µ–∫—Å—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç (–±—É–¥–µ—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω)"]}

        # 1. –û–ë–™–ï–ú
        if len(text) < 200:
            issues.append("‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –º–∞–ª–æ —Ç–µ–∫—Å—Ç–∞")
        elif len(text) < 600:
            score += 5; issues.append("‚ö†Ô∏è –ú–∞–ª–æ –¥–µ—Ç–∞–ª–µ–π")
        else:
            score += 15

        # 2. –°–¢–†–£–ö–¢–£–†–ê
        for kw in ["–æ–±—è–∑–∞–Ω–Ω–æ—Å—Ç", "–∑–∞–¥–∞—á–∏", "–¥–µ–ª–∞—Ç"]:
            if kw in text_lower: score += 10; break
        else:
            issues.append("‚ùì –ù–µ—Ç –±–ª–æ–∫–∞ '–û–±—è–∑–∞–Ω–Ω–æ—Å—Ç–∏'")

        for kw in ["—Ç—Ä–µ–±–æ–≤–∞–Ω", "–∏—â–µ–º", "–Ω–∞–≤—ã–∫–∏"]:
            if kw in text_lower: score += 10; break
        else:
            issues.append("‚ùì –ù–µ—Ç –±–ª–æ–∫–∞ '–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è'")

        for kw in ["—É—Å–ª–æ–≤–∏—è", "–ø—Ä–µ–¥–ª–∞–≥–∞–µ–º", "–æ—Ñ—Ñ–µ—Ä"]:
            if kw in text_lower: score += 10; break
        else:
            issues.append("‚ùì –ù–µ—Ç –±–ª–æ–∫–∞ '–£—Å–ª–æ–≤–∏—è'")

        # 3. –î–ï–¢–ê–õ–ò
        money_words = ["—Ä—É–±", "‚ÇΩ", "–æ–∫–ª–∞–¥", "–¥–æ—Ö–æ–¥", "–∑–∞—Ä–ø–ª–∞—Ç", "–Ω–∞ —Ä—É–∫–∏", "gross", "net"]
        if any(w in text_lower for w in money_words):
            score += 10
            if re.search(r'\d{2,}', text): score += 5  # –¶–∏—Ñ—Ä—ã
        else:
            issues.append("üí∞ –ù–µ —É–∫–∞–∑–∞–Ω–∞ –∑–∞—Ä–ø–ª–∞—Ç–∞")

        if any(w in text_lower for w in ["–≥—Ä–∞—Ñ–∏–∫", "5/2", "2/2", "—É–¥–∞–ª–µ–Ω", "–æ—Ñ–∏—Å", "—Å–º–µ–Ω–Ω—ã–π"]):
            score += 10
        else:
            issues.append("üìÖ –ù–µ —É–∫–∞–∑–∞–Ω –≥—Ä–∞—Ñ–∏–∫")

        if any(w in text_lower for w in ["–æ—Ñ–∏—Å", "–º.", "–≥–æ—Ä–æ–¥", "–∞–¥—Ä–µ—Å"]): score += 5
        if any(w in text_lower for w in ["—Å–≤—è–∑", "–∑–≤–æ–Ω", "–ø–∏—Å–∞—Ç", "–æ—Ç–∫–ª–∏–∫"]): score += 5
        if any(w in text_lower for w in ["—Ç–∫ —Ä—Ñ", "–æ—Ñ–æ—Ä–º–ª–µ–Ω"]): score += 5

        # 4. –û–§–û–†–ú–õ–ï–ù–ò–ï
        if "<ul>" in text or "‚Ä¢" in text or "‚Äî " in text:
            score += 10
        else:
            issues.append("üìÑ –ù–µ—Ç —Å–ø–∏—Å–∫–æ–≤")
        if "<b>" in text or "<strong>" in text: score += 5

        return {"score": min(score, 100), "issues": issues}

    def process_single_vacancy(self, vac_input: VacancyIn, retriever) -> VacancyOut:
        print(f"‚ñ∂Ô∏è Start processing: {vac_input.input_id}", flush=True)
        start_time = time.time()

        # 1. –û—á–∏—Å—Ç–∫–∞ –∏ –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
        in_title = vac_input.title.strip() if vac_input.title else ""
        in_spec = vac_input.specialization.strip() if vac_input.specialization else ""

        # –ß–∏—Å—Ç–∏–º HTML –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å –≤ input
        raw_text = vac_input.text if vac_input.text else ""
        in_text = self._clean_html(raw_text)

        # –ï—Å–ª–∏ –≤–æ–æ–±—â–µ –≤—Å—ë –ø—É—Å—Ç–æ
        if not any([in_title, in_text, in_spec]):
            return VacancyOut(
                input_id=vac_input.input_id,
                rewritten_title="–ü—Ä–∏–º–µ—Ä", rewritten_specialization="IT", rewritten_text="<p>–ü—É—Å—Ç–æ–π –∑–∞–ø—Ä–æ—Å</p>",
                rewrite_notes=["–í–≤–µ–¥–∏—Ç–µ —Ö–æ—Ç—è –±—ã —á—Ç–æ-—Ç–æ"], issues=[], quality_score=0, original_score=0, safety_flags=[],
                low_confidence_retrieval=True
            )

        # 2. –ê–Ω–∞–ª–∏–∑ –ò–°–•–û–î–ù–ò–ö–ê
        analysis = self._analyze_quality(in_text)
        original_score = analysis["score"]
        current_issues = analysis["issues"]

        # 3. –ü–æ–∏—Å–∫ —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–æ–≤ (RAG)
        # –ò—â–µ–º –ø–æ —Ç–æ–º—É, —á—Ç–æ –µ—Å—Ç—å
        search_query = f"{in_title} {in_spec} {in_text[:200]}"
        references = retriever.search(search_query, limit=1) if (retriever and search_query.strip()) else []

        # 4. LLM –ì–µ–Ω–µ—Ä–∞—Ü–∏—è
        # –ù–µ–π—Ä–æ—Å–µ—Ç—å —Å–∞–º–∞ –ø–æ–π–º–µ—Ç, —á—Ç–æ –∑–∞–ø–æ–ª–Ω–∏—Ç—å
        llm_result = self.llm.generate_rewrite(
            user_vacancy={"title": in_title, "text": in_text, "specialization": in_spec},
            references=references,
            issues=current_issues
        )

        final_text = llm_result.get("rewritten_text", in_text)
        final_title = llm_result.get("title", in_title)
        final_spec = llm_result.get("specialization", in_spec)

        # 5. –ê–Ω–∞–ª–∏–∑ –†–ï–ó–£–õ–¨–¢–ê–¢–ê
        final_analysis = self._analyze_quality(final_text)
        final_score = final_analysis["score"]

        # –ï—Å–ª–∏ –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–ª–∏ —Å –Ω—É–ª—è (–±—ã–ª–æ –ø—É—Å—Ç–æ, —Å—Ç–∞–ª–æ –º–Ω–æ–≥–æ) -> —Å—Ç–∞–≤–∏–º –≤—ã—Å–æ–∫—É—é –æ—Ü–µ–Ω–∫—É
        if len(in_text) < 50 and len(final_text) > 500:
            final_score = max(final_score, 90)

        return VacancyOut(
            input_id=vac_input.input_id,
            rewritten_title=final_title,
            rewritten_specialization=final_spec,
            rewritten_text=final_text,
            rewrite_notes=llm_result.get("rewrite_notes", []),
            issues=current_issues,
            quality_score=int(final_score),
            original_score=int(original_score),
            safety_flags=llm_result.get("safety_flags", []),
            low_confidence_retrieval=(len(references) == 0),
            debug={"processing_time": round(time.time() - start_time, 2)}
        )
