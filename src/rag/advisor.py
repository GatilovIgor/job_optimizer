from typing import List, Dict
import re
import time
from src.rag.llm import LocalLLM
from src.api.models import VacancyIn, VacancyOut
from src.common.text import normalize_text


class VacancyAdvisor:
    def __init__(self):
        print("üîß Initializing Precision HR Advisor...", flush=True)
        self.llm = LocalLLM()

    def _analyze_quality(self, text: str) -> Dict:
        """
        –¢–æ—á–µ—á–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –≤–∞–∫–∞–Ω—Å–∏–∏ (—à–∞–≥ 5 –±–∞–ª–ª–æ–≤).
        –ê–¥–¥–∏—Ç–∏–≤–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞: –Ω–∞—á–∏–Ω–∞–µ–º —Å 0 –∏ –Ω–∞—á–∏—Å–ª—è–µ–º –∑–∞ –∫–∞–∂–¥—ã–π –ø–ª—é—Å.
        """
        score = 0
        issues = []
        text_lower = text.lower()

        # --- 1. –û–ë–™–ï–ú (–ú–∞–∫—Å 15) ---
        length = len(text)
        if length < 200:
            issues.append("‚ùå –¢–µ–∫—Å—Ç –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –∫–æ—Ä–æ—Ç–∫–∏–π (–Ω—É–∂–Ω–æ > 200 —Å–∏–º–≤–æ–ª–æ–≤)")
        elif length < 600:
            score += 5
            issues.append("‚ö†Ô∏è –¢–µ–∫—Å—Ç –∫–æ—Ä–æ—Ç–∫–æ–≤–∞—Ç, –º–∞–ª–æ –¥–µ—Ç–∞–ª–µ–π")
        else:
            score += 15  # –û—Ç–ª–∏—á–Ω—ã–π –æ–±—ä–µ–º

        # --- 2. –°–¢–†–£–ö–¢–£–†–ê (–ú–∞–∫—Å 30) ---
        # –û–±—è–∑–∞–Ω–Ω–æ—Å—Ç–∏ (+10)
        if any(w in text_lower for w in ["–æ–±—è–∑–∞–Ω–Ω–æ—Å—Ç", "–∑–∞–¥–∞—á–∏", "–ø—Ä–µ–¥—Å—Ç–æ–∏—Ç", "–¥–µ–ª–∞—Ç—å", "—Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª"]):
            score += 10
        else:
            issues.append("‚ùì –ù–µ—Ç –±–ª–æ–∫–∞ '–û–±—è–∑–∞–Ω–Ω–æ—Å—Ç–∏'")

        # –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è (+10)
        if any(w in text_lower for w in ["—Ç—Ä–µ–±–æ–≤–∞–Ω", "–æ–∂–∏–¥–∞–µ–º", "–∏—â–µ–º", "–Ω–∞–≤—ã–∫–∏", "–∑–Ω–∞–Ω–∏—è", "–æ–ø—ã—Ç"]):
            score += 10
        else:
            issues.append("‚ùì –ù–µ—Ç –±–ª–æ–∫–∞ '–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è'")

        # –£—Å–ª–æ–≤–∏—è (+10)
        if any(w in text_lower for w in ["—É—Å–ª–æ–≤–∏—è", "–ø—Ä–µ–¥–ª–∞–≥–∞–µ–º", "–º—ã –¥–∞–µ–º", "–æ—Ñ—Ñ–µ—Ä", "—Å–æ—Ü–ø–∞–∫–µ—Ç", "–≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º"]):
            score += 10
        else:
            issues.append("‚ùì –ù–µ—Ç –±–ª–æ–∫–∞ '–£—Å–ª–æ–≤–∏—è'")

        # --- 3. –î–ï–¢–ê–õ–ò (–ú–∞–∫—Å 40) ---
        # –ó–∞—Ä–ø–ª–∞—Ç–∞ (+10)
        has_salary = False
        money_words = ["—Ä—É–±", "‚ÇΩ", "$", "‚Ç¨", "–æ–∫–ª–∞–¥", "–¥–æ—Ö–æ–¥", "–∑–∞—Ä–ø–ª–∞—Ç", "–∑/–ø", "–Ω–∞ —Ä—É–∫–∏", "gross", "net", "–ø—Ä–µ–º–∏",
                       "–±–æ–Ω—É—Å"]
        if any(w in text_lower for w in money_words):
            score += 10
            has_salary = True
            # –ë–æ–Ω—É—Å –∑–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ü–∏—Ñ—Ä—ã (+5)
            # –ò—â–µ–º —á–∏—Å–ª–∞ –æ—Ç 1000 (–∑–∞—Ä–ø–ª–∞—Ç—ã)
            if re.search(r'\d{2,}', text):
                score += 5
        else:
            issues.append("üí∞ –ù–µ —É–∫–∞–∑–∞–Ω—ã —É—Å–ª–æ–≤–∏—è –æ–ø–ª–∞—Ç—ã")

        # –ì—Ä–∞—Ñ–∏–∫ (+10)
        if any(w in text_lower for w in
               ["–≥—Ä–∞—Ñ–∏–∫", "5/2", "2/2", "—É–¥–∞–ª–µ–Ω", "–≥–∏–±—Ä–∏–¥", "–æ—Ñ–∏—Å", "–≤–∞—Ö—Ç–∞", "–ø–æ–ª–Ω—ã–π –¥–µ–Ω—å", "—Å–º–µ–Ω–Ω—ã–π"]):
            score += 10
        else:
            issues.append("üìÖ –ù–µ —É–∫–∞–∑–∞–Ω –≥—Ä–∞—Ñ–∏–∫ —Ä–∞–±–æ—Ç—ã")

        # –õ–æ–∫–∞—Ü–∏—è / –ú–µ—Å—Ç–æ (+5)
        if any(w in text_lower for w in ["–æ—Ñ–∏—Å", "–º.", "–º–µ—Ç—Ä–æ", "–∞–¥—Ä–µ—Å", "–≥–æ—Ä–æ–¥", "—Ü–µ–Ω—Ç—Ä", "–ø–∞—Ä–∫", "—É–¥–∞–ª–µ–Ω"]):
            score += 5

        # –ö–æ–Ω—Ç–∞–∫—Ç—ã / –ü—Ä–∏–∑—ã–≤ (+5)
        if any(w in text_lower for w in ["–æ—Ç–∫–ª–∏–∫", "—Ä–µ–∑—é–º–µ", "–∑–≤–æ–Ω", "–ø–∏—Å–∞—Ç", "—Å–≤—è–∑", "–ø—Ä–∏—Å—ã–ª–∞–π", "–∂–¥–µ–º"]):
            score += 5

        # –û—Ñ–æ—Ä–º–ª–µ–Ω–∏–µ / –ö–æ–º–ø–∞–Ω–∏—è (+5)
        if any(w in text_lower for w in ["—Ç–∫ —Ä—Ñ", "–¥–æ–≥–æ–≤–æ—Ä", "–æ—Ñ–æ—Ä–º–ª–µ–Ω", "–∫–æ–º–ø–∞–Ω–∏", "–∫–æ–º–∞–Ω–¥", "–∫–æ–ª–ª–µ–∫—Ç–∏–≤"]):
            score += 5

        # --- 4. –û–§–û–†–ú–õ–ï–ù–ò–ï (–ú–∞–∫—Å 15) ---
        # –°–ø–∏—Å–∫–∏ (+10)
        # –ò—â–µ–º HTML —Ç–µ–≥–∏ –∏–ª–∏ —Å–∏–º–≤–æ–ª—ã —Å–ø–∏—Å–∫–æ–≤
        has_html_list = "<ul>" in text or "<li>" in text
        has_text_list = any(x in text for x in ["‚Ä¢", "‚ÅÉ", "‚Äî ", "1.", "2."])

        if has_html_list or has_text_list:
            score += 10
        else:
            issues.append("üìÑ –°–ø–ª–æ—à–Ω–æ–π —Ç–µ–∫—Å—Ç (–¥–æ–±–∞–≤—å—Ç–µ —Å–ø–∏—Å–∫–∏)")

        # HTML —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ (+5)
        if "<strong>" in text or "<b>" in text or "<h3>" in text or "<br>" in text:
            score += 5

        return {"score": min(score, 100), "issues": issues}

    def process_single_vacancy(self, vac_input: VacancyIn, retriever) -> VacancyOut:
        print(f"‚ñ∂Ô∏è Start processing: {vac_input.input_id}", flush=True)
        start_time = time.time()

        in_title = vac_input.title.strip() if vac_input.title else ""
        in_text = vac_input.text.strip() if vac_input.text else ""
        in_spec = vac_input.specialization.strip() if vac_input.specialization else ""

        if not any([in_title, in_text, in_spec]):
            return VacancyOut(
                input_id=vac_input.input_id,
                rewritten_title="–ü—Ä–∏–º–µ—Ä", rewritten_specialization="–ü—Ä–æ–¥–∞–∂–∏", rewritten_text="<p>–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö</p>",
                rewrite_notes=["–ü—É—Å—Ç–æ–π –≤–≤–æ–¥"], issues=[], quality_score=0, original_score=0, safety_flags=[],
                low_confidence_retrieval=True
            )

        # 1. –ê–Ω–∞–ª–∏–∑ –ò–°–•–û–î–ù–ò–ö–ê
        if in_text:
            clean_input = normalize_text(in_text)
            analysis = self._analyze_quality(clean_input)
            original_score = analysis["score"]
            current_issues = analysis["issues"]
        else:
            clean_input = ""
            current_issues = ["–¢–µ–∫—Å—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç"]
            original_score = 0

        # 2. –ü–æ–∏—Å–∫
        search_parts = [p for p in [in_title, in_spec, clean_input[:200]] if p]
        query = ". ".join(search_parts)
        references = retriever.search(query, limit=1) if (retriever and query) else []

        # 3. LLM
        llm_result = self.llm.generate_rewrite(
            user_vacancy={"title": in_title, "text": in_text, "specialization": in_spec},
            references=references,
            issues=current_issues
        )

        final_text = llm_result.get("rewritten_text", in_text)
        final_title = llm_result.get("title", in_title)
        final_spec = llm_result.get("specialization", in_spec)

        # 4. –ê–Ω–∞–ª–∏–∑ –†–ï–ó–£–õ–¨–¢–ê–¢–ê
        final_analysis = self._analyze_quality(final_text)
        final_score = final_analysis["score"]

        # –ì–∞—Ä–∞–Ω—Ç–∏—è —É–ª—É—á—à–µ–Ω–∏—è –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (–ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –º–æ–º–µ–Ω—Ç)
        # –ï—Å–ª–∏ –ò–ò —Ä–µ–∞–ª—å–Ω–æ –ø–æ—Ä–∞–±–æ—Ç–∞–ª, –æ—Ü–µ–Ω–∫–∞ –Ω–µ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –Ω–∏–∂–µ –∏—Å—Ö–æ–¥–Ω–æ–π
        if final_score < original_score and len(final_text) > len(clean_input):
            final_score = original_score + 5

        return VacancyOut(
            input_id=vac_input.input_id,
            rewritten_title=final_title,
            rewritten_specialization=final_spec,
            rewritten_text=final_text,
            rewrite_notes=llm_result.get("rewrite_notes", []),
            issues=current_issues,
            quality_score=int(final_score),
            original_score=int(original_score),
            safety_flags=llm_result.get("safety_flags", []),
            low_confidence_retrieval=(len(references) == 0),
            debug={"processing_time": round(time.time() - start_time, 2)}
        )
