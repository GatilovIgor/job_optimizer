import pandas as pd
import pathlib
import pickle
import logging
import warnings
from transformers import logging as hf_logging
from sentence_transformers import SentenceTransformer
from sklearn.neighbors import NearestNeighbors
from typing import List, Dict

# --- ðŸ”‡ Ð¢Ð˜Ð¨Ð˜ÐÐ Ð’ Ð­Ð¤Ð˜Ð Ð• ---
# ÐžÑ‚ÐºÐ»ÑŽÑ‡Ð°ÐµÐ¼ Ñ‚ÐµÑ…Ð½Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ Ð¿Ñ€ÐµÐ´ÑƒÐ¿Ñ€ÐµÐ¶Ð´ÐµÐ½Ð¸Ñ HuggingFace Ð¸ Ð»Ð¸ÑˆÐ½Ð¸Ð¹ ÑˆÑƒÐ¼
hf_logging.set_verbosity_error()
logging.getLogger("sentence_transformers").setLevel(logging.ERROR)
warnings.filterwarnings("ignore", category=UserWarning)
warnings.filterwarnings("ignore", category=FutureWarning)


# -------------------------

class VacancyRetriever:
    def __init__(self, data_path: str = None):
        self.root = pathlib.Path(__file__).resolve().parent.parent.parent
        self.index_path = self.root / "data" / "vector_index.pkl"

        # ÐœÐ¾Ð´ÐµÐ»ÑŒ Ð¸Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐµÑ‚ÑÑ ÑƒÐ¶Ðµ Ð² "Ñ‚Ð¸Ñ…Ð¾Ð¼" Ñ€ÐµÐ¶Ð¸Ð¼Ðµ
        self.model = SentenceTransformer("cointegrated/rubert-tiny2")
        self.index = None
        self.vacancies = []

        if self.index_path.exists():
            print("ðŸ“– Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð¿Ð¾Ð¸ÑÐºÐ¾Ð²Ð¾Ð³Ð¾ Ð¸Ð½Ð´ÐµÐºÑÐ°...")
            with open(self.index_path, "rb") as f:
                data = pickle.load(f)
                self.index = data["index"]
                self.vacancies = data["vacancies"]
        elif data_path:
            self._build_index(data_path)
        else:
            print("âš ï¸ ÐÐµÑ‚ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð´Ð»Ñ Ð¿Ð¾Ð¸ÑÐºÐ°. RAG Ð²Ñ‹ÐºÐ»ÑŽÑ‡ÐµÐ½.")

    def _build_index(self, data_path: str):
        print("âš™ï¸ Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ð¸Ð½Ð´ÐµÐºÑÐ° (Ð²ÐµÐºÑ‚Ð¾Ñ€Ð¸Ð·Ð°Ñ†Ð¸Ñ)...")
        df = pd.read_parquet(data_path)

        # Ð¤Ð¸Ð»ÑŒÑ‚Ñ€ÑƒÐµÐ¼ Ñ‚Ð¾Ð¿-Ð¿ÐµÑ€Ñ„Ð¾Ñ€Ð¼ÐµÑ€Ð¾Ð²
        if 'is_top_performer' in df.columns:
            top_df = df[df['is_top_performer'] == True].copy()
        else:
            top_df = df.copy()

        # Ð¤Ð¾Ñ€Ð¼Ð¸Ñ€ÑƒÐµÐ¼ Ñ‚ÐµÐºÑÑ‚
        top_df['embed_text'] = (
                top_df['vacancy_title'].fillna('') + " " +
                top_df['specialization'].fillna('') + " " +
                top_df['vacancy_description'].fillna('').astype(str).str.slice(0, 500)
        )

        # encode Ð¼Ð¾Ð¶ÐµÑ‚ Ð¿Ð¾ÐºÐ°Ð·Ñ‹Ð²Ð°Ñ‚ÑŒ Ð¿Ñ€Ð¾Ð³Ñ€ÐµÑÑ-Ð±Ð°Ñ€, ÐµÐ³Ð¾ Ð¾ÑÑ‚Ð°Ð²Ð¸Ð¼, Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð²Ð¸Ð´ÐµÑ‚ÑŒ, Ñ‡Ñ‚Ð¾ Ð¿Ñ€Ð¾Ñ†ÐµÑÑ Ð¸Ð´ÐµÑ‚
        vectors = self.model.encode(top_df['embed_text'].tolist(), show_progress_bar=True)

        self.index = NearestNeighbors(n_neighbors=5, metric="cosine")
        self.index.fit(vectors)

        self.vacancies = top_df.to_dict("records")

        with open(self.index_path, "wb") as f:
            pickle.dump({"index": self.index, "vacancies": self.vacancies}, f)
        print("âœ… Ð˜Ð½Ð´ÐµÐºÑ Ð³Ð¾Ñ‚Ð¾Ð² Ð¸ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½.")

    def search(self, query: str, limit: int = 3) -> List[Dict]:
        if not self.index: return []

        vec = self.model.encode([query])
        distances, indices = self.index.kneighbors(vec, n_neighbors=limit)

        results = []
        for idx in indices[0]:
            if idx < len(self.vacancies):
                results.append(self.vacancies[idx])
        return results
